---
title: Research
permalink: /research/
layout: single
---

<h4>
Master Thesis</h4>
<a href="https://drive.google.com/file/d/0B2rr9ElbXBeSeU9JOVkxN0Fibjg/view?usp=sharing" target="_blank">Semantic Segmentation for 3D Point Clouds using Deep Learning</a><br />
Abstract:<br />
<blockquote class="tr_bq">
3D LiDAR (Light Detection And Ranging) sensors have been widely used in numerous robotics platforms, and their usage in autonomous driving and advance driver assistance systems (ADAS) is becoming more and more common. Perception in LiDAR sensor data still comprise of classical machine learning pipeline, despite leaps of technical advances in perception methods through the rise of Deep Learning. As Deep learning is transforming the fields of computer vision and natural language processing, a similar breakthrough has not been seen with the methods of perception in 3D point cloud data. This lack of progress is due to the computational burden of 3rd spatial dimension and unavailability of adequate point wise annotated benchmark datasets.<br />
This thesis aims to close this gap, by performing the semantic segmentation of 3D point cloud data from LiDAR sensors using deep learning. In order to train end-to-end deep neural networks, we present a dataset of 3D point clouds from 64 channel LiDAR sensor with point-wise annotations in urban environment. We transform our 3D point cloud data to 2D depth maps to release the computational burden of handling 3rd spatial dimensions. It aids the application of conventional deep convolutional neural networks with 3D point cloud data while keeping the storage complexity in check. Moreover, we design a deep convolutional neural network, CloudSeg, that performs novel 11 class point-wise semantic point cloud segmentation. To the best of our knowledge, this thesis is the first study to perform involved 11 class semantic segmentation of 3D point clouds in urban environment. CloudSeg shows promising quantitative and qualitative results for point-wise semantic point cloud segmentation in urban environment, reliably explaining around 85% of the point cloud in each LiDAR scan. Moreover, we show that our convolutional neural network model can detect large variety of diverse objects using only the data from LiDAR sensors.</blockquote>
<br />
<h4>
</h4>
<h4>
Research work during Bachelor Degree</h4>
<ul>
<li><a href="http://ieeexplore.ieee.org/document/6754607/" target="_blank">ClickSafe/Mitigation and Prevention from Clickjacking â€“ Bachelors Thesis, 15th IEEE International Symposium on High Assurance Systems Engineering, 2014, Miami, Florida, USA. A browser security add-on that mitigate click-jacking using detection system and collaborative user feedback.&nbsp;</a><br />Abstract:<br /><span style="background-color: white; color: #333333;"></span><blockquote class="tr_bq" style="background-color: white; color: #333333; margin-bottom: 1em !important; outline: 0px !important;">
Click jacking is an act of hijacking user clicks in order to perform undesired actions which are beneficial for the attacker. We propose Click safe, a browser-based tool to provide increased security and reliability against click jacking attacks. Click safe is based on three major components. The detection unit detects malicious components in a web page that redirect users to external links. The mitigation unit provides interception of user clicks and give educated warnings to users who can then choose to continue or not. Click safe also incorporate a feedback unit which records the user's actions, converts them into ratings and allows future interactions to be more informed. Click safe is predominant from other similar tools as the detection and mitigation is based on a comprehensive framework which utilizes detection of malicious web components and incorporating user feedback. We explain the mechanism of click safe, describes its performance, and highlights its potential in providing safety against click jacking to a large number of users.</blockquote>
</li>
<li><a href="http://ieeexplore.ieee.org/document/7845067/" target="_blank">Dynamic Gesture Recognition using Machine Learning Techniques and factor affecting its accuracies, 6th International Conference on Innovative Computing Technology (INTECH), 2016, Islamabad, PK</a><br />Abstract:<br /><span style="background-color: white; color: #333333;"></span><blockquote class="tr_bq" style="background-color: white; color: #333333;  margin-bottom: 1em !important; outline: 0px !important;">
Kinect, a motion sensing input device for gaming consoles has been successfully utilized for video games, and rehabilitation of paralyzed patients. We use this device to make learning a fun activity for children. Children learn to draw shapes by moving their hands in front of the Kinect device. We automatically recognize and classify their dynamic hand gestures into predefined shapes, namely; rectangles, triangles, and circles. To decrease over fitting and the cost of generating sample shapes a novel feature engineering approach is also proposed that increases the performance by more than 11%. We used three different machine learning algorithms and successfully classified the shapes with an accuracy of more than 97%.</blockquote>
</li>
</ul>

